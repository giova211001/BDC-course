import com.sun.istack.logging.Logger;
import org.apache.log4j.Level;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.rdd.RDD;
import scala.Tuple2;

import java.io.BufferedReader;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;

/**
 * Specifically, for the homework you must do the following tasks.
 *
 * 1) Write a method/function MRComputeStandardObjective that takes in input an RDD of (point,group) pairs (representing a set ð‘ˆ=ð´âˆªðµ
 * ), and a set ð¶
 *  of centroids, and returns the value of the objective function Î”(ð‘ˆ,ð¶)
 *  described above, thus ignoring the demopgraphic groups.
 *
 * 2) Write a method/function MRComputeFairObjective that takes in input an RDD of (point,group) pairs (representing points of a set ð‘ˆ=ð´âˆªðµ
 * ), and a set ð¶
 *  of centroids, and returns the value of the objective function Î¦(ð´,ðµ,ð¶)
 *  described above.
 *
 * 3) Write a method/function MRPrintStatistics that takes in input an RDD of (point,group) pairs (representing points of a set ð‘ˆ=ð´âˆªðµ
 * ), and a set ð¶
 *  of centroids, and computes and prints the triplets (ð‘ð‘–,ð‘ð´ð‘–,ð‘ðµð‘–)
 * , for 1â‰¤ð‘–â‰¤ð¾=|ð¶|
 * , where ð‘ð‘–
 *  is the ð‘–
 * -th centroid in ð¶
 * , and ð‘ð´ð‘–,ð‘ðµð‘–
 *  are the numbers of points of ð´
 *  and ðµ
 * , respectively, in the cluster ð‘ˆð‘–
 *  centered in ð‘ð‘–
 * .
 *
 * 4) Write a program GxxHW1.java (for Java users) or GxxHW1.py (for Python users), where xx is your 2-digit group number (e.g., 04 or 25), which receives in input, as command-line arguments, a path to the file storing the input points, and 3 integers ð¿,ð¾,ð‘€
 * , and does the following:
 *
 * Prints the command-line arguments and stores  ð¿,ð¾,ð‘€
 *  into suitable variables.
 * Reads the input points into an RDD of (point,group) pairs -called inputPoints-, subdivided into ð¿
 *  partitions.
 * Prints the number ð‘
 *  of points, the number ð‘ð´
 *  of points of group A, and the number ð‘ðµ
 *  of points of group B (hence, ð‘=ð‘ð´+ð‘ðµ
 * ).
 * Computes a set ð¶
 *  of ð¾
 *  centroids by using the Spark implementation of the standard Lloyd's algorithm for the input points, disregarding the points' demographic groups, and using ð‘€
 *  as number of iterations.
 * Prints the values of the two objective functions Î”(ð‘ˆ,ð¶)
 *  and Î¦(ð´,ðµ,ð¶)
 * , computed by running  MRComputeStandardObjective and MRComputeFairObjective, respectively.
 * Runs MRPrintStatistics.
 */



public class G01HW1 {

    public static void main(String[] args) throws IOException {

        /*Check the number of CMD LINE PARAMETERS in order to satisfy the following requirement of the homework
         -> Prints the command-line arguments and stores  ð¿,ð¾,ð‘€ into suitable variables.
         INPUTS:
         1) path to the file storing the input points
         2) L = number of partitions
         3) K = number of desired clusters
         4) M = number of iterations

         */

        if(args.length != 4){
            throw new IllegalArgumentException("USAGE: file_path num_partitions num_cluster num_iterations");
        }


        // Store and print the COMMAND LINE ARGUMENT
        String file_path = args[0];
        int L = Integer.parseInt(args[1]);
        int K = Integer.parseInt(args[2]);
        int M = Integer.parseInt(args[3]);

        System.out.println("File path: " + file_path + "\n" +
                "L (number of partitions): " + L + "\n" +
                "K (number of clusters): " + K + "\n" +
                "M (number of iterations): " + M + "\n");

        /*
            SPARK SETUP
         */

        SparkConf conf = new SparkConf(true).setAppName("G01HW1");
        JavaSparkContext ctx = new JavaSparkContext(conf);
        ctx.setLogLevel("OFF");

        /*
            Store the input file into the RDD and subdivide into L partitions
            textFile method -> transform the input file into an RDD of Strings, whose element correspond to the
            distinct lines of thr file
         */
        JavaRDD<String> input = ctx.textFile(file_path).repartition(L).cache();

        // Setting the GLOBAL VARIABLES
        long points;
        points = input.count();
        System.out.println("Number of inputs: " + points);
        JavaPairRDD<Tuple2<Double, Double>, String> pairs;
        // Convert the input into pairs of the form (point, group)





    }
}
